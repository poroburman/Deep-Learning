{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script uses Convolutional Neural Network to correctly predict whether an image is a cat or a dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# preprocess the training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "# preprocess the testing set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. BUILD AND TRAIN CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.6710 - accuracy: 0.6094 - val_loss: 0.5806 - val_accuracy: 0.7010\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 46s 183ms/step - loss: 0.5877 - accuracy: 0.6842 - val_loss: 0.5838 - val_accuracy: 0.6880\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.5674 - accuracy: 0.7091 - val_loss: 0.5638 - val_accuracy: 0.7065\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.5539 - accuracy: 0.7146 - val_loss: 0.5684 - val_accuracy: 0.7010\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 41s 165ms/step - loss: 0.5368 - accuracy: 0.7247 - val_loss: 0.5379 - val_accuracy: 0.7345\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 41s 162ms/step - loss: 0.5157 - accuracy: 0.7398 - val_loss: 0.5740 - val_accuracy: 0.7105\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.5104 - accuracy: 0.7414 - val_loss: 0.5200 - val_accuracy: 0.7415\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.4931 - accuracy: 0.7635 - val_loss: 0.5086 - val_accuracy: 0.7565\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.4842 - accuracy: 0.7666 - val_loss: 0.5173 - val_accuracy: 0.7555\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.4701 - accuracy: 0.7750 - val_loss: 0.5473 - val_accuracy: 0.7460\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 0.4619 - accuracy: 0.7799 - val_loss: 0.5874 - val_accuracy: 0.7285\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 43s 174ms/step - loss: 0.4545 - accuracy: 0.7885 - val_loss: 0.5428 - val_accuracy: 0.7670\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.4394 - accuracy: 0.7958 - val_loss: 0.6623 - val_accuracy: 0.7295\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.4331 - accuracy: 0.7956 - val_loss: 0.5355 - val_accuracy: 0.7570\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.4266 - accuracy: 0.8029 - val_loss: 0.5081 - val_accuracy: 0.7690\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.4163 - accuracy: 0.8081 - val_loss: 0.5601 - val_accuracy: 0.7485\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.4111 - accuracy: 0.8071 - val_loss: 0.5230 - val_accuracy: 0.7675\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 0.4038 - accuracy: 0.8139 - val_loss: 0.5685 - val_accuracy: 0.7575\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 40s 162ms/step - loss: 0.3906 - accuracy: 0.8239 - val_loss: 0.5283 - val_accuracy: 0.7755\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.3834 - accuracy: 0.8254 - val_loss: 0.5694 - val_accuracy: 0.7625\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.3685 - accuracy: 0.8313 - val_loss: 0.5671 - val_accuracy: 0.7540\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.3697 - accuracy: 0.8317 - val_loss: 0.5494 - val_accuracy: 0.7660\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 43s 174ms/step - loss: 0.3642 - accuracy: 0.8374 - val_loss: 0.5855 - val_accuracy: 0.7670\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.3497 - accuracy: 0.8435 - val_loss: 0.5631 - val_accuracy: 0.7720\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 0.3316 - accuracy: 0.8533 - val_loss: 0.6402 - val_accuracy: 0.7590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14077aa60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize CNN\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# step 1 : convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "\n",
    "# step 2 : pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# step 3 : flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# step 4 : full connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# step 5 : output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# compile CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# train CNN on training set and evaluate it on test set\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MAKE A PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# import image to predict with target size\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "\n",
    "# convert the image to an array\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "# add extra dimension\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "# predict\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "# check which indices corresponds to pictures of dog and cat\n",
    "training_set.class_indices\n",
    "\n",
    "# if else loop for predicting dog or cat\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'\n",
    "\n",
    "# print the prediction\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
